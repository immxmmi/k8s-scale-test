# ğŸš€ KEDA Autoscaling Demo mit Prometheus

Dieses Projekt demonstriert, wie ein Kubernetes Deployment mithilfe von **KEDA** und **Prometheus** automatisch skaliert werden kann â€“ inklusive **Scale-to-Zero**, wenn keine Last vorhanden ist.

## ğŸ”§ Voraussetzungen

- Kubernetes (z.â€¯B. Ã¼ber Minikube)
- Helm installiert
- `kubectl` Zugriff auf den Cluster

## ğŸ“¦ Installation

### 1. Prometheus installieren

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack --namespace prometheus --create-namespace
```

### 2. KEDA installieren

```bash
helm repo add kedacore https://kedacore.github.io/charts
helm repo update
helm install keda kedacore/keda --namespace keda --create-namespace
```

## ğŸ“Š Prometheus UI Port-Forward

```bash
kubectl -n prometheus port-forward services/prometheus-kube-prometheus-prometheus 9090:9090  >/dev/null 2>&1 &
```

## âš™ï¸ KEDA-Anwendung deployen

```bash
kubectl apply -f ./keda/k8s
```

## ğŸ” Metriken Ã¼berprÃ¼fen

```bash
kubectl port-forward svc/keda-demo -n keda-demo 8080:80 >/dev/null 2>&1 &
watch kubectl -n keda-demo get pods 
curl -s http://localhost:8080/metrics | grep http_requests_total
```

## ğŸ§ª Test-Szenario: HTTP-Last erzeugen

Um die automatische Skalierung zu testen, kannst du mit folgendem Befehl eine Last simulieren:

```bash
while true; do curl -s http://localhost:8080 > /dev/null; done
```

Dieser Befehl erzeugt dauerhaft HTTP-Requests gegen den Dienst. KEDA sollte die Anzahl der Pods hochskalieren, sobald die konfigurierten Metrik-Grenzwerte Ã¼berschritten werden.

## âœ… Ziel
Das Deployment wird automatisch hoch- und herunterskaliert â€“ inklusive vollstÃ¤ndigem **Herunterskalieren auf Null**, wenn keine HTTP-Anfragen eingehen.

> â— **Hinweis:** Um tatsÃ¤chlich auf **Null Pods** skalieren zu kÃ¶nnen, muss sichergestellt werden, dass Metriken auch dann verfÃ¼gbar bleiben, wenn keine Pods der Anwendung laufen. 
> 
> Wenn die Anwendung selbst die Metriken liefert, kÃ¶nnen diese bei `0` Pods nicht mehr abgefragt werden. Eine mÃ¶gliche LÃ¶sung wÃ¤re ein Sidecar oder ein separater Metrik-Exporter, der dauerhaft lÃ¤uft â€“ etwa ein NGINX-Proxy, der den Traffic beobachtet und Metriken bereitstellt, da dieser unabhÃ¤ngig von der Anwendung aktiv bleibt.
# ğŸš€ KEDA Autoscaling Demo mit Prometheus

Dieses Projekt demonstriert, wie ein Kubernetes Deployment mithilfe von **KEDA** und **Prometheus** automatisch skaliert werden kann â€“ inklusive **Scale-to-Zero**, wenn keine Last vorhanden ist.

## ğŸ”§ Voraussetzungen

- Kubernetes (z.â€¯B. Ã¼ber Minikube)
- Helm installiert
- `kubectl` Zugriff auf den Cluster

## ğŸ“¦ Installation

### 1. Prometheus installieren

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack --namespace prometheus --create-namespace
```

### 2. KEDA installieren

```bash
helm repo add kedacore https://kedacore.github.io/charts
helm repo update
helm install keda kedacore/keda --namespace keda --create-namespace
```

## ğŸ“Š Prometheus UI starten

```bash
minikube service prometheus-kube-prometheus-prometheus -n prometheus
```

## âš™ï¸ KEDA-Anwendung deployen

```bash
kubectl apply -f ./k8s
minikube service keda-demo -n keda-demo
```

## ğŸ” Metriken Ã¼berprÃ¼fen

```bash
kubectl port-forward svc/keda-demo -n keda-demo 8080:80 >/dev/null 2>&1 &
curl -s http://localhost:8080/metrics | grep http_requests_total
```

## âœ… Ziel
Das Deployment wird automatisch hoch- und herunterskaliert â€“ inklusive vollstÃ¤ndigem **Herunterskalieren auf Null**, wenn keine HTTP-Anfragen eingehen.

> â— **Hinweis:** Um tatsÃ¤chlich auf **Null Pods** skalieren zu kÃ¶nnen, muss sichergestellt werden, dass Metriken auch dann verfÃ¼gbar bleiben, wenn keine Pods der Anwendung laufen. 
> 
> Wenn die Anwendung selbst die Metriken liefert, kÃ¶nnen diese bei `0` Pods nicht mehr abgefragt werden. Eine mÃ¶gliche LÃ¶sung wÃ¤re ein Sidecar oder ein separater Metrik-Exporter, der dauerhaft lÃ¤uft â€“ etwa ein NGINX-Proxy, der den Traffic beobachtet und Metriken bereitstellt, da dieser unabhÃ¤ngig von der Anwendung aktiv bleibt.